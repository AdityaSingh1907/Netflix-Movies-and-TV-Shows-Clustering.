{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaSingh1907/Netflix-Movies-and-TV-Shows-Clustering./blob/main/Netflix_Movies_and_TV_Shows_Clustering_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Netflix Movies and TV Shows Clustering**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name** - Aditya Singh\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary:**\n",
        "This project involves a comprehensive analysis of Netflix content, including movies and TV shows, followed by the development of a movie recommendation system based on content similarity. The project utilizes data cleaning, visualization, clustering, and natural language processing techniques to extract insights from the dataset and provide personalized content recommendations to users.\n",
        "\n",
        "\n",
        "\n",
        "**Technical Documentation:**\n",
        "\n",
        "**1. Introduction:**\n",
        "\n",
        "The project aims to analyze Netflix's extensive collection of movies and TV shows to uncover patterns, trends, and preferences among viewers. Additionally, it implements a recommendation system that suggests content based on the descriptions of previously watched shows or movies.\n",
        "\n",
        "**2. Data Collection and Overview:**\n",
        "\n",
        "The dataset consists of 7,787 rows and 12 columns, with information about each title, including title, director, cast, country, date added, release year, rating, duration, genre, and description.\n",
        "\n",
        "**3. Data Preprocessing:**\n",
        "\n",
        "Missing data: Null values in columns like 'cast' and 'country' were handled by filling them appropriately. Rows with null values in 'date_added' and 'rating' were dropped.\n",
        "Feature engineering: Ratings were grouped into categories.\n",
        "Unnecessary columns: The 'director' column was removed as it was not relevant for the analysis.\n",
        "\n",
        "**4. Data Exploration:**\n",
        "\n",
        "Visualizations were created to understand the distribution and trends in Netflix content.\n",
        "Key insights include a higher number of movies compared to TV shows, the growth of content over the years, and the distribution of content by ratings and genres.\n",
        "**5. Clustering Analysis:**\n",
        "\n",
        "K-means clustering was applied to group content based on the descriptions.\n",
        "Evaluation metrics like Silhouette Score and Davies-Bouldin Score were used to assess the quality of clusters.\n",
        "\n",
        "**6. Movie Recommendation System:**\n",
        "\n",
        "The recommendation system was built using spaCy and cosine similarity based on word vectors.\n",
        "Word vectors were created for all descriptions in the dataset.\n",
        "Recommendations are provided by finding the most similar content descriptions based on cosine similarity.\n",
        "Users can input a movie or TV show title, and the system suggests top recommendations.\n",
        "\n",
        "**7. Future Enhancements:**\n",
        "\n",
        "The recommendation system can be improved by incorporating user feedback and collaborative filtering.\n",
        "External data sources or additional features, such as user preferences, could enhance recommendation accuracy.\n",
        "\n",
        "**8. Implementation Details:**\n",
        "\n",
        "The project was implemented using Python and various libraries, including pandas, matplotlib, scikit-learn, and spaCy.\n",
        "The code provides step-by-step explanations and is well-documented for easy understanding and replication."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.**\n",
        "\n",
        "**In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.**\n",
        "\n",
        "**Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.**\n",
        "\n",
        "\n",
        "**In this project, you are required to do**\n",
        "\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Understanding what type content is available in different countries\n",
        "\n",
        "Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting the google drive to access the files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "I4YhfxnVwkNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "file_path='/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(),cbar=True)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total null values\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "8uTqFlajePQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above dataset has 7787 rows and 12 columns. There are total 3631 Missing Values/Null Values in director column,cast column,country column and date_added column and no duplicate values in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "*   type : Identifier - A Movie or TV Show\n",
        "\n",
        "*   title : Title of the Movie / Tv Show\n",
        "\n",
        "*   director : Director of the Movie\n",
        "\n",
        "*   cast : Actors involved in the movie / show\n",
        "\n",
        "*   country : Country where the movie / show was produced\n",
        "\n",
        "*   date_added : Date it was added on Netflix\n",
        "\n",
        "*   release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "*   rating : TV Rating of the movie / show\n",
        "\n",
        "*   duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "*   listed_in : Genere\n",
        "\n",
        "*   description: The Summary description\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create a copy of the current dataset\n",
        "df.copy()\n",
        "#check for the Null Values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Null Values\n",
        "df['cast'].fillna(value='No cast',inplace=True)\n",
        "df['country'].fillna(value=df['country'].mode()[0],inplace=True)\n"
      ],
      "metadata": {
        "id": "FDtweVLsHcAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'date_added' and 'rating' contains an insignificant portion of the data so we will drop them from the dataset\n",
        "df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "j7nAQtZNHu9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since there are many crows with nan director, we have filled it using empty string\n",
        "df['director']=df['director'].fillna('')"
      ],
      "metadata": {
        "id": "FnI5oO_LHxP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#again checking is there any null values are not\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Q2uFCxT9H5Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating']"
      ],
      "metadata": {
        "id": "qGigNB0Ly8-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning the Ratings into grouped categories\n",
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "df['target_ages'] = df['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "PwSVEXGpy6mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type should be a catego\n",
        "df['type'] = pd.Categorical(df['type'])\n",
        "df['target_ages'] = pd.Categorical(df['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])"
      ],
      "metadata": {
        "id": "VWR916BAzF_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "2gq9baZJzFLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Checked for null values and identified columns with missing data.\n",
        "2.  Filled missing values in the 'cast' column with \"No cast\".\n",
        "1.  Filled missing values in the 'country' column with the mode.\n",
        "2.  Dropped rows with null values in 'date_added' and 'rating' columns.\n",
        "1.  Dropped the 'director' column entirely.\n",
        "1.  Assigned the Ratings into grouped categories\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 - Count of Movies and TV Shows on Netflix"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].value_counts()"
      ],
      "metadata": {
        "id": "5oDwNT5tdeH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#countplot to visualize the number of movies and tv_shows in type column\n",
        "# Data\n",
        "content_types = ['Movies', 'TV Shows']\n",
        "counts = [5372, 2398]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(content_types, counts, color=['blue', 'green'])\n",
        "plt.title('Count of Movies and TV Shows on Netflix')\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "al3aL3wWdvMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparing the counts of movies and TV shows, I used bar chart . Bar charts are useful for comparing discrete categories, in this case, the two content types. The distinct bars for movies and TV shows make it easy to compare their counts visually.Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has 5372 movies and 2398 TV shows, there are more number movies on Netflix than TV shows."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insight about the higher number of movies than TV shows can help Netflix refine their content strategy, enhance user experiences, attract new subscribers, and make more informed decisions that positively impact their business.\n",
        "\n",
        "They can adjust their content acquisition and production strategy to match viewer preferences and maintain a balanced library.\n",
        "\n",
        "Highlighting popular TV shows in marketing can attract new subscribers looking for that content.\n",
        "\n",
        "Understanding their unique content mix helps Netflix position themselves effectively against competitors."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 - Content Type Trends Over Years"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#creating two extra columns\n",
        "tv_shows=df[df['type']=='TV Show']\n",
        "movies=df[df['type']=='Movie']\n",
        "\n",
        "# Group the data by 'release_year' and 'type' columns and count occurrences\n",
        "type_count_by_year = df.groupby(['release_year', 'type']).size().unstack().fillna(0)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(type_count_by_year.index, type_count_by_year['Movie'], marker='o', label='Movies')\n",
        "plt.plot(type_count_by_year.index, type_count_by_year['TV Show'], marker='o', label='TV Shows')\n",
        "\n",
        "plt.title('Content Type Trends Over Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Analysing how many movies released per year in last 20 years by using countplot\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y=movies['release_year'],data=df,order=movies['release_year'].value_counts().index[0:20])\n",
        "plt.title('Movies released per year in last 20 year')\n",
        "\n",
        "#Analysing how many movies released per year in last 15 years\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(y=tv_shows['release_year'],data=df,order=tv_shows['release_year'].value_counts().index[0:20])\n",
        "plt.title('TV Shows released per year in last 15 years')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used line plot and Countplot to visualize the count of TV shows and movies over the years. A line plot is suitable for showing trends and changes over a continuous variable (years in this case). The connection between data points on the line helps us understand how the count of each content type evolves over time.\n",
        "\n",
        "A countplot displays the distribution of movies released each year in the last 20 years, providing insight into yearly production patterns.\n",
        "\n",
        "Both charts were chosen for their ability to convey trends and patterns in a visually clear manner."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  2017 and 2018 had the highest number of movies released on Netflix.\n",
        "*  2020 also saw a significant number of movie releases.\n",
        "*  The number of movies on Netflix has been growing faster than the number of TV shows.\n",
        "*  There was a notable increase in both movies and TV show releases after 2015.\n",
        "*   There's a substantial drop in the number of movies and TV show releases after 2020.\n",
        "* It's evident that Netflix has focused more on increasing movie content compared to TV shows.  \n",
        "*  Movies have experienced a much more dramatic increase than TV shows.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights provide valuable information for content planning, user engagement strategies, and business decisions. The observations about content growth, shifts in focus, and production trends can guide Netflix's content acquisition and production strategies in the future."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 - Visualization of Content Ratings for TV Shows and Movies"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#Rating based on rating system of all TV Shows\n",
        "tv_ratings = tv_shows.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "fig_dims = (10,7)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "plt.title('TV Show Ratings',size='20')\n",
        "plt.show()\n",
        "\n",
        "#Movie Ratings based on Target Age Groups\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title('movie ratings')\n",
        "sns.countplot(x=movies['rating'],hue=movies['target_ages'],data=movies,order=movies['rating'].value_counts().index)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TV Show Ratings Visualization, I've used Point plot Chart.\n",
        "\n",
        "Reason: A point plot is suitable for showing the distribution of TV show ratings, where each point represents the count of TV shows with a specific rating. This allows for a clear comparison of ratings and their frequency.\n",
        "\n",
        "And for Movie Ratings by Target Age Group Visualization, I've used Grouped count plot.\n",
        "\n",
        "Reason: A grouped count plot is effective for comparing movie ratings based on different target age groups. It allows you to visualize the count of movies in each rating category, grouped by target age, making it easy to identify patterns and preferences.\n",
        "\n",
        "Both chart types were chosen to best represent the data and highlight the relationships between variables while keeping the visualizations clear and easy to interpret."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The insight i've gained from visualizations is that , TV-MA has the highest number of ratings for tv shows and Movies i,e adult ratings in both the cases TV-MA has the highest number of ratings.\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight can be valuable for Netflix's content strategy, as it suggests that adult-oriented content, such as mature themes and content suitable for a mature audience, has been well-received by viewers. It could influence decisions related to the acquisition and production of content that aligns with this rating category."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 - Visualization of Top Countries with Most Content on Netflix"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Group the data by 'country' and count occurrences\n",
        "country_content_count = df['country'].value_counts()\n",
        "\n",
        "# Select top N countries for visualization\n",
        "top_countries = country_content_count.head(10)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_countries.plot(kind='bar', color='skyblue')\n",
        "plt.title('Top Countries with Most Content on Netflix')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Number of Titles')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pick this specific chart because it's a simple and effective way to compare the number of titles (movies and TV shows) among the top countries on Netflix. The height of the bars directly shows the content count for each country, making it easy to see which countries have the most content."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "United states has the highest number of content on the netflix ,followed by india."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes,the insights gained about content distribution on Netflix, particularly the high content counts in the United States and India, can positively impact the business. It helps in tailoring content strategies, improving user engagement, guiding localization efforts, and potentially attracting more subscribers, leading to increased revenue and a competitive edge."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Geographical Content Distribution And Type Of Content"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly import tools\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "from plotly.subplots import make_subplots"
      ],
      "metadata": {
        "id": "v00CQ2W76sph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all country df\n",
        "all_countries = df.groupby(['country','type']).count()['show_id'].reset_index()\n",
        "all_countries.head()"
      ],
      "metadata": {
        "id": "TlbecmOv8Vkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#country wise content for top countries\n",
        "country_count = {}\n",
        "for i in range(len(all_countries)):\n",
        "    l = all_countries['country'][i].split(', ')\n",
        "    for x in l:\n",
        "        x = re.sub('[^A-Za-z0-9 ]+', '', x)\n",
        "        if x not in country_count.keys():\n",
        "            country_count[x] = all_countries['show_id'][i]\n",
        "        else:\n",
        "            country_count[x] += all_countries['show_id'][i]\n",
        "country_df = pd.DataFrame(list(zip(country_count.keys(), country_count.values())), columns =['country', 'count'])\n",
        "\n",
        "d = country_df.sort_values(by=['count'], ascending=False).head(10)\n",
        "# .plot.bar(x='country',y='count',edgecolor='black')\n",
        "fig = px.bar(d, x='country',y='count')\n",
        "fig.update_traces(marker_color='#221F1F', marker_line_color='#E50914',\n",
        "                  marker_line_width=2, opacity=1)\n",
        "fig.update_layout(title='Content produced country wise')\n",
        "fig.show()\n",
        "top_30 = country_df.sort_values(by=['count'], ascending=False)['country'].head(30)"
      ],
      "metadata": {
        "id": "MiGihWFD8YL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code for Count of Content per country and Content type using world map\n",
        "# Group the data by 'country' and count occurrences\n",
        "country_count = df['country'].value_counts().to_dict()\n",
        "\n",
        "# Create a DataFrame for country and count\n",
        "country_df = pd.DataFrame(list(country_count.items()), columns=['country', 'count'])\n",
        "\n",
        "# Create a dictionary to map country to content type\n",
        "country_type_mapping = df.groupby('country')['type'].unique().apply(lambda x: ', '.join(x)).to_dict()\n",
        "\n",
        "# Modify the code to include type of content in hover text\n",
        "trace = go.Choropleth(\n",
        "    locations=list(country_count.keys()),\n",
        "    locationmode='country names',\n",
        "    z=list(country_count.values()),\n",
        "    text=[f'{country_df[\"country\"][i]}<br>{country_type_mapping[country_df[\"country\"][i]]}' for i in range(len(country_df))],\n",
        "    reversescale=False,\n",
        "    zauto=True,\n",
        "    colorscale='RdBu',\n",
        "    marker=dict(\n",
        "        line=dict(\n",
        "            color='rgb(0,0,0)',\n",
        "            width=0.5)\n",
        "    ),\n",
        "    colorbar=dict(\n",
        "        title='Total Content',\n",
        "        tickprefix='')\n",
        ")\n",
        "\n",
        "data = [trace]\n",
        "layout = go.Layout(\n",
        "    title='Total content per country',\n",
        "    geo=dict(\n",
        "        showframe=True,\n",
        "        showlakes=False,\n",
        "        showcoastlines=True,\n",
        "    )\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Distribution of movies and Tv-Shows genres"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#country wise genre\n",
        "all_countries = df[['country','listed_in']]\n",
        "all_countries.head()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing top10 genre of the movies\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Top10 Genre of Movies',fontweight=\"bold\")\n",
        "sns.countplot(y=movies['listed_in'],data=movies,order=movies['listed_in'].value_counts().index[0:10])"
      ],
      "metadata": {
        "id": "aaoM0slHfZPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Documentaries are the top most genre in netflix which is fllowed by standup comedy and Drams and international movies**\n"
      ],
      "metadata": {
        "id": "LohIzKnVtR1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing top10 genres of TVSHOWS\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Top10 Genre of TV Shows',fontweight=\"bold\")\n",
        "sns.countplot(y=tv_shows['listed_in'],data=tv_shows,order=tv_shows['listed_in'].value_counts().index[0:10])"
      ],
      "metadata": {
        "id": "LGoDxBHpqiyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Analysing top10 genres of TVSHOWS, we can say that the kids tv is the top most TV show genre in netflix**\n"
      ],
      "metadata": {
        "id": "62PKOFQgtgz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Word Clouds"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "#word cloud imports\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "#word cloud for user rating review\n",
        "def func_select_Category(category_name,category_column,column_of_choice):\n",
        "  df_word_cloud = df[[category_column,column_of_choice]].dropna()\n",
        "  df_word_cloud = df_word_cloud[df_word_cloud[category_column]==category_name]\n",
        "  text = \" \".join(word for word in df_word_cloud[column_of_choice])\n",
        "  # Create stopword list:\n",
        "  stopwords = set(STOPWORDS)\n",
        "  # Generate a word cloud image\n",
        "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "  # Display the generated image:\n",
        "  # the matplotlib way:\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Cloud for Movie on Description Column\n",
        "func_select_Category('Movie','type','description')"
      ],
      "metadata": {
        "id": "fZDPexYF3VJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference:Most words like Life, family popping up**"
      ],
      "metadata": {
        "id": "tNnArpy-4BnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Cloud for TV Shows on Description Colum\n",
        "func_select_Category('TV Show','type','description')"
      ],
      "metadata": {
        "id": "ZOVkj92L3lO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference:Most words like Life, family popping up like movies before!**"
      ],
      "metadata": {
        "id": "ypdnllBE4OOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Preparing data for heatmap\n",
        "df['count'] = 1\n",
        "data = df.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "\n",
        "\n",
        "df_heatmap = df.loc[df['country'].isin(data)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df_heatmap['target_ages'],normalize = \"index\").T\n",
        "df_heatmap\n",
        "\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain',\n",
        "       'Mexico']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=\"YlGnBu\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mmHLHK8u_oor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation heatmap is a suitable choice when we want to understand the relationships between different numeric variables in a dataset. By visualizing the correlations using a heatmap, we can quickly identify patterns of positive or negative relationships between variables. This helps in revealing potential multicollinearity or dependencies among features, which is valuable for tasks such as feature selection, identifying redundant variables, or understanding potential influences on target variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the US and UK are closely aligned with their Netflix target ages, but radically different from, example, India or Japan!\n",
        "\n",
        "Also, Mexico and Spain have similar content on Netflix for different age groups."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 1: The average duration of TV shows on Netflix is significantly different from the average duration of movies.\n",
        "\n",
        "Statement 2: The distribution of content ratings on Netflix is independent of the content type (movies or TV shows).\n",
        "\n",
        "Statement 3: There is a significant difference in the distribution of content ratings among the top three countries with the most content on Netflix."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing scipy.stats module for statistical hypothesis testing\n",
        "from scipy import stats\n",
        "#making copy of df_clean_frame\n",
        "df_hypothesis=df.copy()\n",
        "#head of df_hypothesis\n",
        "df_hypothesis.head()"
      ],
      "metadata": {
        "id": "Z86NQdsA24k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1 -The average duration of TV shows on Netflix is significantly different from the average duration of movies."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The average duration of TV shows on Netflix is equal to the average duration of movies.\n",
        "\n",
        "Alternative Hypothesis (H1): The average duration of TV shows on Netflix is not equal to the average duration of movies."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Convert the 'duration' column to numeric\n",
        "tv_shows['duration'] = pd.to_numeric(tv_shows['duration'], errors='coerce')\n",
        "movies['duration'] = pd.to_numeric(movies['duration'], errors='coerce')\n",
        "\n",
        "\n",
        "# Perform t-test for equality of means\n",
        "t_stat, p_value = stats.ttest_ind(tv_shows['duration'], movies['duration'], equal_var=False)\n",
        "\n",
        "# Set significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Check if p-value is less than alpha\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The average duration of TV shows is significantly different from movies.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in duration between TV shows and movies.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test performed to obtain the p-value, the Independent Samples T-Test, It's a parametric test used to determine if there is a significant difference between the means of two independent groups (in this case, the average duration of TV shows and movies on Netflix)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific statistical test, Welch's t-test, was chosen because it's appropriate for comparing the means of two independent groups (TV shows and movies) when there might be unequal variances or sample sizes."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2 -The distribution of content ratings on Netflix is independent of the content type (movies or TV shows)."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The distribution of content ratings on Netflix is independent of the content type (movies or TV shows).\n",
        "\n",
        "Alternative Hypothesis (H1): The distribution of content ratings on Netflix is dependent on the content type."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table of content ratings and content type\n",
        "contingency_table = pd.crosstab(df['rating'], df['type'])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "# Set significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Check if p-value is less than alpha\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The distribution of content ratings is dependent on content type.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The distribution of content ratings is independent of content type.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value in this case is the chi-squared test. This test is used to determine if there is an association between two categorical variables, in this case, content ratings and content types (movies or TV shows)."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The chi-square test chosen because it's appropriate for analyzing the independence of two categorical variables, which suits the hypothesis being tested here - the relationship between content ratings and content types on Netflix."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3 -There is a significant difference in the distribution of content ratings among the top three countries with the most content on Netflix."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The distribution of content ratings among the top three countries with the most content on Netflix is the same.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in the distribution of content ratings among these countries."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import kruskal\n",
        "\n",
        "# Select the top three countries with the most content\n",
        "top_countries = df['country'].value_counts().head(3).index.tolist()\n",
        "\n",
        "# Create subsets for each country\n",
        "country_data = [df[df['country'] == country]['rating'] for country in top_countries]\n",
        "\n",
        "# Perform Kruskal-Wallis test\n",
        "H, p_value = kruskal(*country_data)\n",
        "\n",
        "# Set significance level (e.g., 0.05)\n",
        "alpha = 0.05\n",
        "\n",
        "# Check if p-value is less than alpha\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in content ratings among the top three countries.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The distribution of content ratings is the same among the top three countries.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Kruskal-Wallis test to obtain the p-value for the hypothesis test. This test is a non-parametric method used to determine whether there are statistically significant differences between the distributions of three or more groups. In this case, it was used to determine if there is a significant difference in content ratings among the top three countries with the most content on Netflix."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the Kruskal-Wallis test is robust and does not assume equal variances or that the data follows a specific distribution, making it a suitable choice for non-parametric data like content ratings.\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#Checking Missing Values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values to handle in the given dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "import re\n",
        "# Define a dictionary of common English contractions and their expanded forms\n",
        "contractions_dict = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\",\n",
        "    \"I'll\": \"I will\",\n",
        "    \"I'm\": \"I am\",\n",
        "    \"I've\": \"I have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"that'll\": \"that will\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"who'd\": \"who would\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who're\": \"who are\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "# Function to expand contractions in a text\n",
        "def expand_contractions(text, contractions_dict):\n",
        "    words = text.split()\n",
        "    expanded_words = [contractions_dict.get(word.lower(), word) for word in words]\n",
        "    return \" \".join(expanded_words)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "text_with_contractions = \"I can't believe it's raining. You're going to the party, aren't you?\"\n",
        "expanded_text = expand_contractions(text_with_contractions, contractions_dict)\n",
        "print(expanded_text)\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#combining all text column to single text column to work with\n",
        "df['filtered'] = df['description'] + ' '+ df['listed_in'] + ' ' + df['rating'] + ' '+ df['country']+ ' ' + df['cast'] + ' '+ df['director']"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all text to lowercase\n",
        "df['filtered'] = df['filtered'].str.lower()"
      ],
      "metadata": {
        "id": "A2f9P1UventI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "# Define a function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Apply the function to the 'description' column\n",
        "df['filtered'] = df['filtered'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['filtered'][0]"
      ],
      "metadata": {
        "id": "0uj-o8JDOLRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "# Define a function to remove URLs and words containing digits\n",
        "def remove_urls_and_digits(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing digits\n",
        "    return text\n",
        "\n",
        "# Apply the function to the 'description' column\n",
        "df['filtered'] = df['filtered'].apply(remove_urls_and_digits)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['filtered']"
      ],
      "metadata": {
        "id": "9ptg-A-IOafy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_k0GRlOOiC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#necessary import for nlp\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "OXdVkh3jhvxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "stemmer = SnowballStemmer('english')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "jyAiXZFBiGyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "id": "QtLFoAipLQgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to Remove Stopwords\n",
        "def wordfilter(string, filtwords):\n",
        "    filtered = []\n",
        "    tokens = word_tokenize(string)\n",
        "    for word in tokens:\n",
        "        if word not in filtwords:\n",
        "            filtered.append(stemmer.stem(word))\n",
        "    return filtered\n",
        "\n",
        "df['filtered_new'] = ''\n",
        "for item, row in df.iterrows():\n",
        "    df.at[item, 'filtered_new'] = wordfilter(row['filtered'], stop_words)\n",
        "\n",
        "df['filtered_new']"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Define a function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Apply the function to the 'description' column\n",
        "df['filtered_new'] = df['filtered'].apply(tokenize_text)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['filtered_new']"
      ],
      "metadata": {
        "id": "TeRHuF3gNYrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#join words fun\n",
        "def join_words(x):\n",
        "  return \" \".join(x)"
      ],
      "metadata": {
        "id": "y5wAm-5TPIrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final column\n",
        "df['filtered_new'] = df['filtered_new'].apply(join_words)"
      ],
      "metadata": {
        "id": "q31PwwYvPVDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "KD8b0gwiP4IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = df.filtered_new"
      ],
      "metadata": {
        "id": "Ny79HSU_Qo0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using tfidf for Vectorizing Text\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "t_vectorizer = TfidfVectorizer(max_df = 0.9,min_df = 1, max_features=15000)\n",
        "X= t_vectorizer.fit_transform(words)\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "yYelKhMfRG42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "UqBgf_6aU2f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the TF-IDF (Term Frequency-Inverse Document Frequency) text vectorization technique because it's a widely used method that helps represent the importance of words in a document relative to a collection of documents. It's particularly useful for tasks like information retrieval, text classification, and clustering, making it suitable for various text analysis purposes."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA for Dimensionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing PCA for Dimensionality Reduction\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#PCA code\n",
        "transformer = PCA()\n",
        "transformer.fit(X.toarray())"
      ],
      "metadata": {
        "id": "O5g1A7vUTtpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explained var v/s comp\n",
        "plt.plot(np.cumsum(transformer.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')"
      ],
      "metadata": {
        "id": "HmLsmlyiVGJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that clearly in the above graph the data with 3000 components cover 80% variance."
      ],
      "metadata": {
        "id": "RCqAu_3cXsFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#choosing right dim from plot, this might take a while, for ready ans use n_components = 3000\n",
        "from sklearn.decomposition import PCA\n",
        "transformer = PCA(n_components=3000)\n",
        "transformer.fit(X.toarray())\n",
        "X_transformed = transformer.transform(X.toarray())\n",
        "X_transformed.shape"
      ],
      "metadata": {
        "id": "46ynVvF3VzKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorizing the test and train\n",
        "X_vectorized = t_vectorizer.transform(words)"
      ],
      "metadata": {
        "id": "GXKiFUWdV9Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#applying pca\n",
        "X= transformer.transform(X_vectorized.toarray())"
      ],
      "metadata": {
        "id": "PH7-2YDNV-dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "rf5oMu73WCJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **K Means Clustering**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finding optimal number of clusters using the elbow method\n",
        "from sklearn.cluster import KMeans\n",
        "wcss_list= []  #Initializing the list for the values of WCSS\n",
        "\n",
        "#Using for loop for iterations from 1 to 30.\n",
        "for i in range(1, 30):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 42)\n",
        "    kmeans.fit(X)\n",
        "    wcss_list.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 30), wcss_list)\n",
        "plt.title('The Elobw Method Graph')\n",
        "plt.xlabel('Number of clusters(k)')\n",
        "plt.ylabel('wcss_list')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "#sillhoute score of clusters\n",
        "sill = []\n",
        "for i in range(2,30):\n",
        "    model = KMeans(n_clusters=i,init ='k-means++',random_state=51)\n",
        "    model.fit(X)\n",
        "    y1 = model.predict(X)\n",
        "    score = silhouette_score(X,y1)\n",
        "    sill.append(score)\n",
        "    print('cluster: %d \\t Sillhoute: %0.4f'%(i,score))"
      ],
      "metadata": {
        "id": "isKswIf-edZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Silhouette's score\n",
        "plt.plot(sill, 'bs--')\n",
        "plt.xticks(list(range(2, 30)))  # Set tick locations to match the labels\n",
        "plt.grid()\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ABxmicxfemxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the K-means model on a dataset\n",
        "kmeans = KMeans(n_clusters= 26, init='k-means++', random_state= 42)\n",
        "y_predict= kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "bo0KXEGTfjqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**\n"
      ],
      "metadata": {
        "id": "Kut1rxjVNiEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the clusters and evaluate the silhouette score\n",
        "\n",
        "score = silhouette_score(X, y_predict)\n",
        "print(\"Silhouette score is {}\".format(score))"
      ],
      "metadata": {
        "id": "6rG_k1WpNg83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#davies_bouldin_score of our clusters\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_predict)"
      ],
      "metadata": {
        "id": "g56d8RXHOxCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding a seperate column for the cluster\n",
        "df[\"cluster\"] = y_predict"
      ],
      "metadata": {
        "id": "AvZOIJkEO7th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'].value_counts()"
      ],
      "metadata": {
        "id": "t0p5qUDAPAbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict the labels of clusters.\n",
        "label = kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "USEXCBC4rvlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Getting unique labels\n",
        "u_labels = np.unique(label)\n",
        "\n",
        "# Create a colormap with enough distinct colors\n",
        "colors = plt.cm.jet(np.linspace(0, 1, len(u_labels)))\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plotting the results with different colors for each cluster:\n",
        "for i, color in zip(u_labels, colors):\n",
        "    plt.scatter(X[label == i, 0], X[label == i, 1], label=i, c=[color])\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Clustering Results\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vI19CDW-r6uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kmeans label to cluster column\n",
        "df['cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "N9hIBpYljqcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "5BiQ5mNpsgZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word Cloud & Clusters"
      ],
      "metadata": {
        "id": "MZHuoBFQprh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word cloud for user rating review\n",
        "def func_select_Category(category_name,column_of_choice):\n",
        "  df_word_cloud = df[['cluster',column_of_choice]].dropna()\n",
        "  df_word_cloud = df_word_cloud[df_word_cloud['cluster']==category_name]\n",
        "  text = \" \".join(word for word in df_word_cloud[column_of_choice])\n",
        "  # Create stopword list:\n",
        "  stopwords = set(STOPWORDS)\n",
        "  # Generate a word cloud image\n",
        "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "  # Display the generated image:\n",
        "  # the matplotlib way:\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "OP0jPOrNkZWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud on Description col for different cluster"
      ],
      "metadata": {
        "id": "xjPEsFZ1l_52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(26):\n",
        "  func_select_Category(i,'description')"
      ],
      "metadata": {
        "id": "Qw_yjHdXlsyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud on Cast col for different cluster"
      ],
      "metadata": {
        "id": "N8kMeUIfmYNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(26):\n",
        "  func_select_Category(i,'cast')"
      ],
      "metadata": {
        "id": "mc26vqVJmNXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud on director col for different cluster"
      ],
      "metadata": {
        "id": "sDzIBw4om0kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(9):\n",
        "  func_select_Category(i,'director')"
      ],
      "metadata": {
        "id": "G1RactD2myvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud on listed in col for different cluster"
      ],
      "metadata": {
        "id": "lZQ-tbUPsmfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "  func_select_Category(i,'listed_in')"
      ],
      "metadata": {
        "id": "oqeeX7ONsq7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud on Country col for different cluster"
      ],
      "metadata": {
        "id": "2Dh3XrxNnGp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "  func_select_Category(i,'country')"
      ],
      "metadata": {
        "id": "a9cxbzjFnIxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud on Title col for different cluster"
      ],
      "metadata": {
        "id": "pfV0O43-nbBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "  func_select_Category(i,'title')"
      ],
      "metadata": {
        "id": "Xi0kw89tnouD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 0 : Drama Enthusiasts"
      ],
      "metadata": {
        "id": "xOxTwsoayWNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 0][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "UwcLvyfvyXdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 1 : Sci-Fi Lovers"
      ],
      "metadata": {
        "id": "0P1WfgnHzaX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 1][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "TJZjVIuRzlVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 2 : Comedy Central"
      ],
      "metadata": {
        "id": "Zae5dJKp0C8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 2][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "A1HmMmVT0JpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 3 : Documentary Buffs"
      ],
      "metadata": {
        "id": "0gLfyblg0T2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 3][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "zTZyox8c0TFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 4 : International Treasures"
      ],
      "metadata": {
        "id": "NtPx4MNo0olh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 4][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "pSXiRWuW0rx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 5 : Action Mania"
      ],
      "metadata": {
        "id": "AxLPgrgx0skg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 5][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "PQHsRYR10t0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 6 : Kids' Corners"
      ],
      "metadata": {
        "id": "DDxB27Np0vD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 6][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "ZhzPpQib0wBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 7 : Mystery & Thrill"
      ],
      "metadata": {
        "id": "gY0g7y560xND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 7][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "LairFBrG0yg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 8 : Classic Cinema"
      ],
      "metadata": {
        "id": "xE6aHfuJ0zpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 8][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "Eo6qh10G008K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster 9 : Reality TV"
      ],
      "metadata": {
        "id": "QLT9GDuP012h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['cluster'] == 9][['type','title','director','cast','country','rating','listed_in','description']]"
      ],
      "metadata": {
        "id": "I0Rbq28-03EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualization for Clusters using Bokeh!!!**"
      ],
      "metadata": {
        "id": "cDtour-ixcDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "x_embedded = TSNE(n_components=2).fit_transform(X)\n",
        "\n",
        "x_embedded.shape"
      ],
      "metadata": {
        "id": "eWzL7eoayxow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import for bokeh\n",
        "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, CustomJS\n",
        "from bokeh.palettes import Category20\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.io import output_file, show\n",
        "from bokeh.transform import transform\n",
        "from bokeh.io import output_notebook\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.layouts import column\n",
        "from bokeh.models import RadioButtonGroup\n",
        "from bokeh.models import TextInput\n",
        "from bokeh.layouts import gridplot\n",
        "from bokeh.models import Div\n",
        "from bokeh.models import Paragraph\n",
        "from bokeh.layouts import column\n"
      ],
      "metadata": {
        "id": "ylmbIW1N5NOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_notebook()\n",
        "y_labels = label\n",
        "\n",
        "# data sources\n",
        "source = ColumnDataSource(data=dict(\n",
        "    x= x_embedded[:,0],\n",
        "    y= x_embedded[:,1],\n",
        "    x_backup = x_embedded[:,0],\n",
        "    y_backup = x_embedded[:,1],\n",
        "    desc= y_labels,\n",
        "    titles= df['title'],\n",
        "    directors = df['director'],\n",
        "    cast = df['cast'],\n",
        "    description = df['description'],\n",
        "    listed_in = df['listed_in'],\n",
        "    rating = df['rating'],\n",
        "    country = df['country'],\n",
        "    labels = [\"C-\" + str(x) for x in y_labels]\n",
        "    ))"
      ],
      "metadata": {
        "id": "FCaqaEqgCao_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hover over information\n",
        "hover = HoverTool(tooltips=[\n",
        "    (\"Title\", \"@titles\"),\n",
        "    (\"Director(s)\", \"@directors\"),\n",
        "    (\"Cast\", \"@cast\"),\n",
        "    (\"Description\", \"@description\"),\n",
        "    (\"listed_in\",\"@listed_in\"),\n",
        "    (\"rating\",\"@rating\"),\n",
        "    (\"country\",\"@country\")\n",
        "],\n",
        "                 point_policy=\"follow_mouse\")\n",
        "\n",
        "# map colors\n",
        "mapper = linear_cmap(field_name='desc',\n",
        "                     palette=Category20[20],\n",
        "                     low=min(y_labels) ,high=max(y_labels))\n",
        "\n",
        "\n",
        "# prepare the figure\n",
        "p = figure(width=800, height=800,\n",
        "           tools=[hover, 'pan', 'wheel_zoom', 'box_zoom', 'reset'],\n",
        "           title=\"Netflix Movies and Tv Shows\",\n",
        "           toolbar_location=\"right\")\n",
        "\n",
        "# plot\n",
        "p.scatter('x', 'y', size=5,\n",
        "          source=source,\n",
        "          fill_color=mapper,\n",
        "          line_alpha=0.3,\n",
        "          line_color=\"black\",\n",
        "          legend_field='labels')\n",
        "\n",
        "# option\n",
        "option = RadioButtonGroup(labels=[\"C-0\", \"C-1\", \"C-2\",\n",
        "                                  \"C-3\", \"C-4\", \"C-5\",\n",
        "                                  \"C-6\", \"C-7\", \"C-8\",\n",
        "                                  ],\n",
        "                          active=9)\n",
        "\n",
        "# search box\n",
        "#keyword = TextInput(title=\"Search:\", callback=keyword_callback)\n",
        "#header\n",
        "header = Div(text=\"\"\"<h1>Find similar movies / tv shows in corresponding Cluster</h1>\"\"\")\n",
        "\n",
        "# show\n",
        "show(column(header,p))"
      ],
      "metadata": {
        "id": "aIH4VH-Vom_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "hg4vBpvjvPXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dendogram"
      ],
      "metadata": {
        "id": "aBMjYSfYyGYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.cluster.hierarchy as shc\n",
        "plt.figure(figsize =(8, 8))\n",
        "plt.title('Visualising the data')\n",
        "Dendrogram = shc.dendrogram((shc.linkage(X, method ='ward')))"
      ],
      "metadata": {
        "id": "IzdcNtUgy2uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hierarchical Clustering"
      ],
      "metadata": {
        "id": "cAKaxtIXzBUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Agglomerative Clustering"
      ],
      "metadata": {
        "id": "BTk7yYr10Po-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting our variable in Agglomerative Clusters\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "aggh = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')\n",
        "aggh.fit(X)\n",
        "#Predicting using our model\n",
        "y_hc=aggh.fit_predict(X)"
      ],
      "metadata": {
        "id": "We7-6DE1zAbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hierarchical =df.copy()\n",
        "#creating a column where each row is assigned to their separate cluster\n",
        "df_hierarchical['cluster'] = aggh.labels_\n",
        "df_hierarchical.head()\n"
      ],
      "metadata": {
        "id": "-xv8pTs50_3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "nTcGuGyC1IiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Silhouette Coefficient\n",
        "print(\"Silhouette Coefficient: %0.3f\"%silhouette_score(X,y_hc, metric='euclidean'))\n"
      ],
      "metadata": {
        "id": "X8ipixo31L5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#davies_bouldin_score of our clusters\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "davies_bouldin_score(X, y_hc)"
      ],
      "metadata": {
        "id": "VirNaT3V1Uku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movie Recommendation System"
      ],
      "metadata": {
        "id": "DVUjAu3Q17U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl"
      ],
      "metadata": {
        "id": "t2ZrgmKN5Jvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "F190CxAF_Lg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.examples import sentences\n",
        "#!pip install en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "bKI5IaYL_msc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create word vectors for all movies and TV show descriptions\n",
        "with nlp.disable_pipes():\n",
        "    vectors = np.array([nlp(film.description).vector for idx, film in df.iterrows()])"
      ],
      "metadata": {
        "id": "YPGEfvGX_n-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to analyze how similar two word vectors are\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b)/np.sqrt(a.dot(a)*b.dot(b))"
      ],
      "metadata": {
        "id": "_CJivbg7_zmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean for all word vectors\n",
        "vec_mean = vectors.mean(axis=0)\n",
        "\n",
        "# Subtract the mean from the vectors\n",
        "centered = vectors - vec_mean"
      ],
      "metadata": {
        "id": "G0zL3xUF_5SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the indices of the five most similar descriptions\n",
        "def get_similar_description_indices(description_vec):\n",
        "\n",
        "    # Calculate similarities between given description and other descriptions in the dataset\n",
        "    sims = np.array([cosine_similarity(description_vec - vec_mean, vec) for vec in centered])\n",
        "\n",
        "    # Get the indices of the five most similar descriptions\n",
        "    most_similar_index = np.argsort(sims)[-6:-1]\n",
        "\n",
        "    return most_similar_index"
      ],
      "metadata": {
        "id": "n7n-fi5WACd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create array of lists containing indices of five most similar descriptions\n",
        "similar_indices = np.array([get_similar_description_indices(vec) for vec in vectors])\n"
      ],
      "metadata": {
        "id": "jqPVnqXQAJ0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_indices"
      ],
      "metadata": {
        "id": "M6g6xhZCASsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_index = df.index[df.title == \"3%\"][0]\n",
        "\n",
        "print(\"Chosen Movie/TV Show\")\n",
        "print(df.title[test_index] + ': ' + df.description[test_index] + '\\n')\n",
        "print(\"Top Recommendations\")\n",
        "print(df.title[similar_indices[test_index][4]] + ': ' + df.description[similar_indices[test_index][4]] + '\\n')\n",
        "print(df.title[similar_indices[test_index][3]] + ': ' + df.description[similar_indices[test_index][3]] + '\\n')\n",
        "print(df.title[similar_indices[test_index][2]] + ': ' + df.description[similar_indices[test_index][2]] + '\\n')\n",
        "print(df.title[similar_indices[test_index][1]] + ': ' + df.description[similar_indices[test_index][1]] + '\\n')\n",
        "print(df.title[similar_indices[test_index][0]] + ': ' + df.description[similar_indices[test_index][0]] + '\\n')"
      ],
      "metadata": {
        "id": "AuIfQJ6hASGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the project's conclusions:\n",
        "\n",
        "**Data Overview:**The dataset contains information on 7787 movies and TV shows available on Netflix, with 12 columns providing details such as title, director, cast, country, date added, release year, rating, duration, genre, and description.\n",
        "\n",
        "**Data Wrangling:**\n",
        "Missing values were identified and handled in columns like 'cast' and 'country'.\n",
        "Rows with null values in 'date_added' and 'rating' columns were dropped.\n",
        "The 'director' column was dropped entirely.\n",
        "Ratings were grouped into categories.\n",
        "\n",
        "**Data Exploration:**Various visualizations were created to understand trends and relationships in the data.\n",
        "Notable insights included the prevalence of movies over TV shows, trends in content type over the years, and distribution of content by ratings and genres.\n",
        "\n",
        "**Cluster Analysis:**\n",
        "K-means clustering was performed to group movies and TV shows based on their descriptions.\n",
        "The Silhouette Score and Davies-Bouldin Score were used to evaluate the quality of the clusters.\n",
        "\n",
        "**Movie Recommendation System:**\n",
        "A content-based recommendation system was implemented using spaCy and cosine similarity based on word vectors.\n",
        "The system provides top recommendations for a chosen movie or TV show based on similarity of their descriptions.\n",
        "\n",
        "**Conclusion:**\n",
        "The project successfully explored, cleaned, and analyzed the Netflix dataset.\n",
        "Clustering revealed distinct groups of content based on their descriptions.\n",
        "The recommendation system provides personalized suggestions based on similar content descriptions.\n",
        "\n",
        "**Next Steps:**\n",
        "Further refinement of the recommendation system could involve user feedback and collaborative filtering.\n",
        "Additional features or external data sources could be incorporated for more accurate clustering and recommendations.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}